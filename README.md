# Eagle: Real-Time Football Tracking and Aggregation
## Introduction
Eagle converts football broadcast data from television feeds to tracking data useful for analysis and visualisation. It uses a collection of custom trained models and a variety of computer vision techniques to identify, track and obtain player and ball coordinates from each frame of broadcast data.

Unlike other solutions, Eagle is designed to work **directly on broadcast data** and does not require special scouting feeds or angles. It can read and process clips directly from matches.

**Note on this Fork:** This repository has been heavily modified to run as a **real-time, multi-threaded inference pipeline**. It consumes a live HLS stream with timed ID3 metadata, performs object tracking, and generates both a live annotated video (with minimap) and a per-second aggregated JSON file. The instructions below are specific to this real-time HLS demo.

For more information on the original algorithm, refer to the [documentation](docs/algorithm.md).

---

## Real-Time HLS Tracking and Aggregation Demo

This section details how to run the `main.py` script for live HLS processing.

### Features

* **Multi-Threaded Pipeline:** Uses four distinct threads (Reader, Worker, Metadata Listener, Display) to ensure the high-FPS stream (25 FPS) is read correctly while the slower ML model (e.g., 8-10 FPS) processes frames without blocking.
* **Accurate Live Annotations:** The video display is locked to the model's processing speed, ensuring that all annotations (player ellipses, ball, field lines) are **perfectly synchronized** with the frame they are drawn on.
* **Live Minimap:** Generates a real-time, top-down tactical minimap by calculating the perspective transform (homography) from the field keypoints.
* **Metadata-Driven Aggregation:** Ingests timed ID3 metadata from the HLS stream to trigger a data aggregation event *exactly* once per second.
* **Per-Second Averaging:** Averages all player and ball coordinates detected within a one-second window and saves them to a JSON file.
* **Custom JSON Formatting:** Outputs aggregated data into a specific JSON schema, including timestamps, field boundaries, and coordinate lists.
* **Robust Stream Handling:** Automatically waits for the live stream to start and gracefully shuts down all threads when the stream ends or 'q' is pressed.

### How It Works: The 4-Thread Architecture

This project cannot consume a standard VOD (Video-on-Demand) file because it relies on metadata arriving in real-time. The required 3-terminal setup creates a "VOD-to-Live" pipeline.

Inside the Python script (`main.py`), a 4-thread architecture manages the data flow:

1.  **Thread 1: Reader (`frame_reader`)**
    * Reads frames from the HLS stream at 25 FPS.
    * Puts the *most recent* frame into the `job_queue` (a buffer of size 1).

2.  **Thread 2: Metadata Listener (`metadata_listener`)**
    * Listens to the HLS stream *only* for ID3 metadata tags.
    * Puts a unique timestamp string (e.g., `18:54:20:00`) into the `metadata_queue` once per second.

3.  **Thread 3: Worker (`process_worker`)**
    * This is the **bottleneck**. It pulls the latest frame from the `job_queue` as fast as it can (e.g., 8-10 FPS).
    * Runs the heavy `model.process_single_frame()`.
    * Puts the *original frame + its processed data* into the `result_queue`.

4.  **Thread 4: Main/Display (`main_realtime`)**
    * Waits and pulls finished, processed frames from the `result_queue` (at 8-10 FPS).
    * Displays the annotated frame (resulting in a low-FPS, but 100% accurate, video).
    * Listens to the `metadata_queue` to trigger data aggregation.

### Requirements

* Python 3.10+
* All libraries from `requirements.txt` (including `torch`, `opencv-python`, `av`, `numpy`, `scipy`).
* **FFmpeg:** This must be installed on your system and available in your PATH.
* **An HLS VOD Stream Source:** This script is designed to run against the VOD stream generated by the [Org-id3 project](https://github.com/JacobJEdwards/Org-id3).

### How to Run

This project **requires three separate terminals** to run correctly, started in a specific order to prevent stream mismatches.

#### Step 1: Terminal 1 - Host the VOD Stream

First, you must serve the source HLS VOD files from your `Org-id3` project.

1.  Navigate to the directory where your VOD files (`.m3u8`, `.ts`) are located.
    ```bash
    cd /path/to/Org-id3/output_hls
    ```
2.  Start a basic Python web server.
    ```bash
    python3 -m http.server 8000
    ```
3.  Leave this terminal running.

#### Step 2: Terminal 2 - Start This Python Project

This is the main processing script. We start it *before* FFmpeg so it can wait for the stream to begin.

1.  Navigate to this project's directory.
    ```bash
    cd /path/to/Eagle
    ```
2.  Run the `main.py` script.
    ```bash
    python main.py --video_path "live_stream/live.m3u8" --output_dir "output"
    ```
3.  You will see a small black window pop up, and the terminal will print:
    `Main: Waiting for video stream at live_stream/live.m3u8...`

#### Step 3: Terminal 3 - Start the FFmpeg Live Stream

This command pulls from Terminal 1 (VOD) and creates a *new, true live stream* that Terminal 2 (Python) is waiting to consume.

1.  Navigate to this project's directory.
    ```bash
    cd /path/to/Eagle
    ```
2.  Run the FFmpeg VOD-to-Live command. This maps *all* streams (video + data) from the input and re-streams them in real-time.
    ```bash
    ffmpeg -re \
        -i http://localhost:8000/prog_index.m3u8 \
        -c copy \
        -map 0 \
        -f hls \
        -hls_time 1 \
        -hls_list_size 10 \
        -hls_flags delete_segments \
        live_stream/live.m3u8
    ```

#### Step 4: Watch and Stop

* As soon as you run the FFmpeg command, the script in Terminal 2 will detect the stream and begin.
* Two windows will appear: **"Eagle Real-Time Tracking"** (the main video) and **"Minimap"** (the tactical view).
* The video will be low-FPS, but the annotations will be perfectly synchronized.
* To stop, press **'q'** on either OpenCV window. All three threads will shut down gracefully and save the output files.

### Project Outputs

When the script finishes, you will find two files in the `output/` directory:

1.  `annotated_demo_video.mp4`
    * A video file of the annotated output you saw on screen.
    * **Note:** The framerate of this video will match your model's processing speed (e.g., 8.2 FPS), *not* 25 FPS. This is intentional, as it proves the annotations are perfectly synchronized with the frames.
2.  `aggregated_per_second_data.json`
    * A JSON file containing the per-second aggregated data, formatted according to your specific requirements (Timestamp, Boundaries, Coordinates, etc.).

---

## Example Use Cases (from Original Eagle Framework)
The data generated by this pipeline can be used to create a variety of visualisations and metrics. Here are some examples from the original `Eagle` project.

### Voronoi DiagramÂ 
Eagle can be used to create Voronoi diagrams of the pitch. This is useful for visualising the movement of players and the areas they occupy on the pitch. The example here is from Manchester City's goal against Nottingham Forest.

<table align="center">
 <tr>
  <td align="center" valign="middle"><img src="assets/mancity.gif" width="400" alt="Manchester City vs Nottingham Forest"/></td>
  <td align="center" valign="middle"><img src="assets/voronoi.png" width="400" alt="Voronoi Diagram"/></td>
 </tr>
</table>

### Pass Plot
Eagle can be used to create pass trajectories. This can be used to create metrics related to the nature of any single pass. The example here is Lamine Yamal's assist during the Euros.

<table align="center">
 <tr>
  <td align="center" valign="middle"><img src="assets/lamine_yamal.gif" width="400" alt="Lamine Yamal assist 
during Euros"/></td>
  <td align="center" valign="middle"><img src="assets/pass.png" width="400" alt="Pass Trajectory Plot"/></td>
 </tr>
</table>

### Player Trajectory
Eagle can be used to visualize the movement of a player over time. This can be useful for metrics such as distance covered, speed, etc and can also be used to see how players position. The example here is Lionel Messi's goal against Athletic Bilbao.

<table align="center">
 <tr>
  <td align="center" valign="middle"><img src="assets/messi.gif" width="400" alt="Lionel Messi goal vs Athletic Bilbao"/></td>
  <td align="center" valign="middle"><img src="assets/trajectory.png" width="400" alt="Player Trajectory 
Visualization"/></td>
 </tr>
</table>

## Local Installation
If you want to run Eagle locally, first install [uv](https://docs.astral.sh/uv/getting-started/installation/)
```bash
curl -LsSf [https://astral.sh/uv/install.sh](https://astral.sh/uv/install.sh) | sh